{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all tables from manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = f'/user_data/vayzenbe/GitHub_Repos/hemispace' #CHANGE AS NEEEDED CAUSE ITS FOR VLAAAD\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,curr_dir)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "import statsmodels.api as s\n",
    "from sklearn import metrics\n",
    "\n",
    "import pdb\n",
    "import hemispace_params as params\n",
    "\n",
    "\n",
    "\n",
    "#hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = params.data_dir\n",
    "results_dir = params.results_dir\n",
    "fig_dir = params.fig_dir\n",
    "\n",
    "\n",
    "task_info = params.task_info\n",
    "\n",
    "suf = params.suf\n",
    "rois = params.rois\n",
    "hemis = params.hemis\n",
    "\n",
    "\n",
    "\n",
    "#load subject info\n",
    "sub_info = pd.read_csv(f'{curr_dir}/sub_info.csv')\n",
    "\n",
    "\n",
    "\n",
    "sub_info = params.sub_info\n",
    "#extract patients only\n",
    "sub_info = sub_info[sub_info['group'] == 'patient']\n",
    "\n",
    "alpha = .05\n",
    "#mni = load_mni152_brain_mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table for confounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ROI tSNR\n",
    "'''\n",
    "data_type = 'tsnr'\n",
    "data_names = ['tSNR']\n",
    "sum_type = 'confound'\n",
    "\n",
    "rois = ['ventral_visual_cortex','dorsal_visual_cortex']\n",
    "\n",
    "    #print(val, sum_type, sum_name)\n",
    "\n",
    "\n",
    "data_summary = pd.read_csv(f'{results_dir}/{sum_type}/{sum_type}_summary_roi.csv')\n",
    "patient_summary = pd.DataFrame(columns = ['sub_code', 'hemi', ] + rois)\n",
    "patient_percentiles = pd.DataFrame(columns = ['sub_code', 'hemi',] + rois)\n",
    "#extract patients only\n",
    "data_summary = data_summary[data_summary['group'] == 'patient']\n",
    "\n",
    "# for each sub in data_summary, get the sub's code from sub_info\n",
    "for sub in data_summary['sub'].unique():\n",
    "    sub_code = sub_info[sub_info['sub'] == sub]['code'].values[0]\n",
    "    data_summary.loc[data_summary['sub'] == sub, 'sub_code'] = sub_code\n",
    "\n",
    "#drop nan rows\n",
    "data_summary = data_summary.dropna()\n",
    "\n",
    "#replace control tsnr with mean for each sub\n",
    "for roi in data_summary['roi'].unique():\n",
    "    for sub in data_summary['sub'].unique():\n",
    "        mean_tsnr = data_summary[(data_summary['sub'] == sub) & (data_summary['roi'] == roi)]['tsnr'].mean()\n",
    "        data_summary.loc[(data_summary['sub'] == sub) & (data_summary['roi'] == roi), 'tsnr'] = mean_tsnr\n",
    "\n",
    "#drop task column\n",
    "data_summary = data_summary.drop(columns = ['task', 'rot','trans'])\n",
    "\n",
    "\n",
    "\n",
    "#reset index\n",
    "data_summary = data_summary.reset_index(drop = True)\n",
    "\n",
    "#drop duplicates\n",
    "data_summary = data_summary.drop_duplicates()\n",
    "    \n",
    "for code, hemi in zip(sub_info['code'], sub_info['intact_hemi']):\n",
    "\n",
    "    patient_vals = []\n",
    "    patient_percs = []\n",
    "\n",
    "    patient_data = data_summary[(data_summary['sub_code'] == code)]\n",
    "    #loop through condition for each patient    \n",
    "    for roi in rois:\n",
    "        roi_data = patient_data[patient_data['roi'] == roi]\n",
    "        act_resamples = pd.read_csv(f'{results_dir}/{sum_type}/{sum_type}_resamples_{roi}_roi.csv')\n",
    "\n",
    "        control_data = act_resamples[data_type]\n",
    "\n",
    "        #calcualte 95% CI for control data\n",
    "        control_ci = np.percentile(control_data, [(alpha/2)*100, 100-((alpha/2)*100)])\n",
    "            #calcualte patients percentile relative to controls\n",
    "        patient_perc = stats.percentileofscore(control_data, roi_data[data_type].values[0])\n",
    "        \n",
    "\n",
    "        #if patient data is outside of control CI, add to table\n",
    "        #only do if below control distribution\n",
    "        if data_type == 'rot' or data_type == 'trans':\n",
    "            if patient_data[data_type].values[0] > control_ci[1]:\n",
    "                current_val = '*'\n",
    "            else:\n",
    "                current_val  = '-'\n",
    "        elif data_type == 'tsnr':\n",
    "            if roi_data[data_type].values[0] < control_ci[0]:\n",
    "                current_val = '*'\n",
    "            else:\n",
    "                current_val  = '-'\n",
    "\n",
    "        patient_vals.append(current_val)\n",
    "        patient_percs.append(patient_perc)\n",
    "\n",
    "    #add to dataframe\n",
    "    patient_vals = [code, hemi] + patient_vals\n",
    "    patient_percs = [code, hemi] + patient_percs\n",
    "\n",
    "    \n",
    "    patient_summary.loc[len(patient_summary)] = patient_vals\n",
    "    patient_percentiles.loc[len(patient_percentiles)] = patient_percs\n",
    "\n",
    "#capitalize hemi\n",
    "patient_summary['hemi'] = patient_summary['hemi'].str.capitalize()\n",
    "\n",
    "#save\n",
    "patient_summary.to_csv(f'{results_dir}/tables/tsnr_summary_roi_patients.csv', index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tsnr data\n",
    "tsnr_summary = pd.read_csv(f'{results_dir}/confound/confound_summary_roi.csv')\n",
    "#extract just patients\n",
    "tsnr_summary = tsnr_summary[tsnr_summary['group'] == 'patient']\n",
    "\n",
    "#drop nan rows\n",
    "tsnr_summary = tsnr_summary.dropna()\n",
    "\n",
    "#drop task column\n",
    "tsnr_summary = tsnr_summary.drop(columns = ['task', 'rot','trans'])\n",
    "\n",
    "#replace control tsnr with mean for each sub\n",
    "for roi in tsnr_summary['roi'].unique():\n",
    "    for sub in tsnr_summary['sub'].unique():\n",
    "        mean_tsnr = tsnr_summary[(tsnr_summary['sub'] == sub) & (tsnr_summary['roi'] == roi)]['tsnr'].mean()\n",
    "        tsnr_summary.loc[(tsnr_summary['sub'] == sub) & (tsnr_summary['roi'] == roi), 'tsnr'] = mean_tsnr\n",
    "\n",
    "#drop duplicates\n",
    "tsnr_summary = tsnr_summary.drop_duplicates()\n",
    "\n",
    "#reset index\n",
    "tsnr_summary = tsnr_summary.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Whole brain confounds\n",
    "'''\n",
    "\n",
    "data_types = ['tsnr','rot','trans']\n",
    "data_names = ['tSNR', 'Rotation', 'Translation']\n",
    "sum_type = 'confound'\n",
    "\n",
    "    #print(val, sum_type, sum_name)\n",
    "act_resamples = pd.read_csv(f'{results_dir}/{sum_type}/{sum_type}_resamples{suf}.csv')\n",
    "\n",
    "data_summary = pd.read_csv(f'{results_dir}/{sum_type}/{sum_type}_summary{suf}.csv')\n",
    "patient_summary = pd.DataFrame(columns = ['sub_code', 'hemi', ] + data_names)\n",
    "patient_percentiles = pd.DataFrame(columns = ['sub_code', 'hemi',] + data_names)\n",
    "#extract patients only\n",
    "data_summary = data_summary[data_summary['group'] == 'patient']\n",
    "\n",
    "# for each sub in data_summary, get the sub's code from sub_info\n",
    "for sub in data_summary['sub'].unique():\n",
    "    sub_code = sub_info[sub_info['sub'] == sub]['code'].values[0]\n",
    "    data_summary.loc[data_summary['sub'] == sub, 'sub_code'] = sub_code\n",
    "\n",
    "\n",
    "for code, hemi in zip(sub_info['code'], sub_info['intact_hemi']):\n",
    "\n",
    "    patient_vals = []\n",
    "    patient_percs = []\n",
    "\n",
    "    patient_data = data_summary[(data_summary['sub_code'] == code)]\n",
    "    #loop through condition for each patient    \n",
    "    for data_type, data_name in zip(data_types, data_names):\n",
    "\n",
    "        control_data = act_resamples[data_type]\n",
    "\n",
    "        #calcualte 95% CI for control data\n",
    "        control_ci = np.percentile(control_data, [(alpha/2)*100, 100-((alpha/2)*100)])\n",
    "            #calcualte patients percentile relative to controls\n",
    "        patient_perc = stats.percentileofscore(control_data, patient_data[data_type].values[0])\n",
    "        \n",
    "\n",
    "        #if patient data is outside of control CI, add to table\n",
    "        #only do if below control distribution\n",
    "        if data_type == 'rot' or data_type == 'trans':\n",
    "            if patient_data[data_type].values[0] > control_ci[1]:\n",
    "                current_val = '*'\n",
    "            else:\n",
    "                current_val  = '-'\n",
    "        elif data_type == 'tsnr':\n",
    "            if patient_data[data_type].values[0] < control_ci[0]:\n",
    "                current_val = '*'\n",
    "            else:\n",
    "                current_val  = '-'\n",
    "\n",
    "        patient_vals.append(current_val)\n",
    "        patient_percs.append(patient_perc)\n",
    "\n",
    "    #add to dataframe\n",
    "    patient_vals = [code, hemi] + patient_vals\n",
    "    patient_percs = [code, hemi] + patient_percs\n",
    "\n",
    "    \n",
    "    patient_summary.loc[len(patient_summary)] = patient_vals\n",
    "    patient_percentiles.loc[len(patient_percentiles)] = patient_percs\n",
    "\n",
    "#capitalize hemi\n",
    "patient_summary['hemi'] = patient_summary['hemi'].str.capitalize()\n",
    "        \n",
    "#save\n",
    "patient_summary.to_csv(f'{results_dir}/tables/{sum_type}_summary_patients_full_hemi.csv', index = False)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate percentiles and summary for selectivity and decoding measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a table with symbols indicating whether htey are inside or outside distribution for each condition and ROI\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "table_names = ['primary','hemi']\n",
    "\n",
    "all_conds = [['word', 'face', 'tool', 'space'],['word', 'face', 'tool', 'space'],['word', 'face', 'tool', 'space']]\n",
    "all_rois = [['ventral_visual_cortex', 'ventral_visual_cortex', 'dorsal_visual_cortex', 'dorsal_visual_cortex'], \n",
    "        ['hemi','hemi','hemi','hemi']]\n",
    "\n",
    "summary_val = ['sum_selec_norm', 'mean_act', 'volume', 'acc']\n",
    "summary_type = ['selectivity','selectivity','selectivity','decoding']\n",
    "summary_name = ['Summed Selectivity', 'Activation', 'Volume', 'Decoding']\n",
    "cols = ['word_left', 'word_right','','face_left', 'face_right','', 'tool_left', 'tool_right','', 'space_left', 'space_right','']\n",
    "\n",
    "\n",
    "for val, sum_type, sum_name in zip(summary_val, summary_type,summary_name):\n",
    "\n",
    "    for table_name in enumerate(table_names):\n",
    "        conds = all_conds[table_name[0]]\n",
    "        rois = all_rois[table_name[0]]\n",
    "\n",
    "        patient_summary = pd.DataFrame(columns = ['sub_code', 'hemi', 'analysis'] + cols)\n",
    "        patient_percentiles = pd.DataFrame(columns = ['sub_code', 'hemi', 'analysis'] + cols)\n",
    "        for code, hemi in zip(sub_info['code'], sub_info['intact_hemi']):\n",
    "        \n",
    "\n",
    "        \n",
    "            #print(val, sum_type, sum_name)\n",
    "            act_resamples = pd.read_csv(f'{results_dir}/{sum_type}/resamples/{val}_resamples{suf}.csv')\n",
    "\n",
    "            data_summary = pd.read_csv(f'{results_dir}/{sum_type}/{sum_type}_summary{suf}.csv')\n",
    "\n",
    "            #extract patients only\n",
    "            data_summary = data_summary[data_summary['group'] == 'patient']\n",
    "            patient_vals = []\n",
    "            patient_percs = []\n",
    "            # for each sub in data_summary, get the sub's code from sub_info\n",
    "            for sub in data_summary['sub'].unique():\n",
    "                sub_code = sub_info[sub_info['sub'] == sub]['code'].values[0]\n",
    "                data_summary.loc[data_summary['sub'] == sub, 'sub_code'] = sub_code\n",
    "\n",
    "            #loop through condition for each patient    \n",
    "            for cond, roi in zip(conds, rois):\n",
    "                patient_data = data_summary[(data_summary['sub_code'] == code) & (data_summary['cond'] == cond) & (data_summary['roi'] == roi) & (data_summary['hemi'] == hemi)]\n",
    "                #check if patient has data for this condition\n",
    "                if len(patient_data) > 0:\n",
    "                    for control_hemi in hemis:\n",
    "                        control_col = f'{cond}_{control_hemi}_{roi}'\n",
    "                        control_data = act_resamples[control_col]\n",
    "\n",
    "                        #calcualte 95% CI for control data\n",
    "                        control_ci = np.percentile(control_data, [(alpha/2)*100, 100-((alpha/2)*100)])\n",
    "                         #calcualte patients percentile relative to controls\n",
    "                        patient_perc = stats.percentileofscore(control_data, patient_data[val].values[0])\n",
    "                        \n",
    "\n",
    "                        #if patient data is outside of control CI, add to table\n",
    "                        #only do if below control distribution\n",
    "                        if patient_data[val].values[0] < control_ci[0]:\n",
    "                            current_val = '*'\n",
    "                        else:\n",
    "                            current_val  = '-'\n",
    "\n",
    "                        if control_hemi == 'left':\n",
    "                            left_val = current_val\n",
    "                            left_perc = patient_perc\n",
    "                        elif control_hemi == 'right':\n",
    "                            right_val = current_val\n",
    "                            right_perc = patient_perc\n",
    "                        \n",
    "                    patient_vals = patient_vals + [left_val, right_val, ''] # the blank is there to add a break between conditions\n",
    "                    patient_percs = patient_percs + [left_perc, right_perc, '']\n",
    "                else:\n",
    "                    patient_vals = patient_vals + ['n/a', 'n/a', '']\n",
    "                    patient_percs = patient_percs + ['n/a', 'n/a', '']\n",
    "\n",
    "            #add to dataframe\n",
    "            patient_vals = [code, hemi, sum_name] + patient_vals\n",
    "            patient_percs = [code, hemi, sum_name] + patient_percs\n",
    "\n",
    "            \n",
    "            patient_summary.loc[len(patient_summary)] = patient_vals\n",
    "            patient_percentiles.loc[len(patient_percentiles)] = patient_percs\n",
    "\n",
    "        #capitalize hemi\n",
    "        patient_summary['hemi'] = patient_summary['hemi'].str.capitalize()\n",
    "        #save table\n",
    "        patient_summary.to_csv(f'{results_dir}/tables/{val}_summary_{table_name[1]}.csv', index = False)\n",
    "\n",
    "        #capitalize hemi\n",
    "        patient_percentiles['hemi'] = patient_percentiles['hemi'].str.capitalize()\n",
    "        #save table\n",
    "        patient_percentiles.to_csv(f'{results_dir}/tables/{val}_percentiles_{table_name[1]}.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate whether patient peaks are inside the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_type = 'neural_map'\n",
    "\n",
    "conds = ['word_posterior', 'word_anterior', 'face_posterior', 'face_anterior', 'tool_posterior', 'tool_anterior', 'space_posterior', 'space_anterior']\n",
    "val = 'dist'\n",
    "'''Create a table tracking distance'''\n",
    "patient_summary = pd.DataFrame(columns = ['sub_code', 'hemi'] + conds)\n",
    "dist_summary = pd.DataFrame(columns = ['sub_code', 'hemi'] + conds)\n",
    "for code, hemi in zip(sub_info['code'], sub_info['intact_hemi']):\n",
    "\n",
    "    act_resamples = pd.read_csv(f'{results_dir}/{sum_type}/resample_data.csv')\n",
    "\n",
    "    data_summary = pd.read_csv(f'{results_dir}/{sum_type}/patient_dists.csv')\n",
    "\n",
    "    #extract patients only\n",
    "    data_summary = data_summary[data_summary['group'] == 'patient']\n",
    "    patient_vals = []\n",
    "    # for each sub in data_summary, get the sub's code from sub_info\n",
    "    for sub in data_summary['sub'].unique():\n",
    "        sub_code = sub_info[sub_info['sub'] == sub]['code'].values[0]\n",
    "        data_summary.loc[data_summary['sub'] == sub, 'sub_code'] = sub_code\n",
    "\n",
    "    current_vals = []\n",
    "    current_dists = []\n",
    "    #loop through condition for each patient    \n",
    "    for cond in conds:\n",
    "        patient_cond = cond.split('_')\n",
    "        patient_data = data_summary[(data_summary['sub_code'] == code) & (data_summary['cond'] == patient_cond[0]) &  (data_summary['position'] == patient_cond[1])]\n",
    "\n",
    "        control_data = act_resamples[cond]\n",
    "\n",
    "\n",
    "        #calcualte 95% CI for control data\n",
    "        control_ci = np.percentile(control_data, [(alpha/2)*100, 100-((alpha/2)*100)])\n",
    "        \n",
    "\n",
    "        #check if patient has data for this condition\n",
    "        if len(patient_data) > 0:\n",
    "            \n",
    "            #if patient data is outside of control CI, add to table\n",
    "            if patient_data[val].values[0] > control_ci[1]:\n",
    "                current_vals.append('*')\n",
    "            else:\n",
    "                current_vals.append('-')\n",
    "\n",
    "            current_dists.append(patient_data[val].values[0] *3)\n",
    "            \n",
    "        else:\n",
    "            current_vals.append('n/a')\n",
    "            current_dists.append('n/a')\n",
    "\n",
    "\n",
    "\n",
    "    patient_vals = [code, hemi] + current_vals\n",
    "    patient_dists = [code, hemi] + current_dists\n",
    "    #add to dataframe\n",
    "    patient_summary.loc[len(patient_summary)] = patient_vals\n",
    "    dist_summary.loc[len(dist_summary)] = patient_dists\n",
    "\n",
    "    #save\n",
    "    patient_summary.to_csv(f'{results_dir}/tables/{sum_type}_summary.csv', index = False)\n",
    "    dist_summary.to_csv(f'{results_dir}/tables/{sum_type}_dists.csv', index = False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
